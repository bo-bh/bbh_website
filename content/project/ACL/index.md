---
author: Borhane Blili-Hamelin
categories:
- Community
- Algorithmic Accountability
- Participatory research
date: "2022-09-01"
draft: false
excerpt: An open community tackling silos in the algorithmic accountability space through participatory workshops and research

layout: single
links:
- icon: door-open
  icon_pack: fas
  name: ACL Website
  url: https://accountabilitycaselabs.xyz/

subtitle: A participatory approach to challenges in the algorithmic accountability space
tags:
- Open community
- Participatory workshops
- Research
title: Accountability Case Labs
---

In 2021, I founded [Accountability Case Labs (ACL)](https://accountabilitycaselabs.xyz/). 

ACL is an open community exploring participatory approaches to challenges in the algorithmic accountability space.

Our mission is to connect and build common strategic insights across the full range of technical and social experts, researchers, builders, and advocates who care about AI accountability.

We believe that participatory workshops have the power to help bridge gaps and silos among algorithmic accountability practitioners.

  We co-create unique experiences that empower meaningful cross-disciplinary participation. 

  During our first year (2021-2022), we co-designed two unique workshop formats. 

  (1) We built our MVP of three case study based workshops. They each centered case studies of impactful actions we find worth examining for algorithmic accountability practitioners: Twitter’s 2021 Bias Bounty, and the case of a Frye Motion involving ShotSpotter in Illinois courts. We used facilitation techniques inspired by [Open Post Academics’ participatory cross-disciplinary workshops](https://doi.org/10.5281/zenodo.6026972), by speculative design, and by community led storytelling. These workshops each culminated in group reflection on shared insights.

  (2) We also built workshops around our own exploratory research data. From December 2021 to March 2022, ACL conducted research on algorithmic accountability practitioners through interviews and a survey. We wanted to see if we could design participatory workshops that invite participants of different background to collaborate on insights about qualitative interview and quantitative survey data. This resulted in two workshops including one at MozFest.

  We started as part of the first cohort of the [MozFest Civil Society Actors for Trustworthy AI in 2021-2022](https://foundation.mozilla.org/en/blog/making-trustworthy-ai-real/). 
  
  We held two workshops at [Mozilla Festival 2022](https://www.mozillafestival.org/en/), and one at [RightsCon 2022](https://www.rightscon.org).

  We are committed to openness. We strive to release all our outputs under CC BY 4.0 attribution licenses.
   
  You can read a detailed overview of our activities during our first year on the [document linked here.](https://docs.google.com/document/d/1wi-OsM4l2HCn-F0L_PomqkpncT5y9DCQF6db2eMwsCY/edit?usp=sharing) 

To stay tuned about our next steps and our Fall 2022 workshops, [sign up for our mailing list here.](https://forms.gle/5KvPCHECyjPHNUyX7) 

## Our Contributors

Huge thanks to our many contributors! They are:

* Vasundhra Dahiya
* Vanja Skoric
* Tina Lassiter
* Sundar Narayanan
* Sophia Katrenko
* Shlomi Hod
* Shea Brown
* Ranjit Singh
* Pamela Jasper
* Mrin Bhattacharya
* Luke Richards
* Kyle Smith
* Jonathan Poritz
* John Hurst
* Jillian Powers
* Jacqui Ayling
* Itzel Amieva
* Gina Helfrich
* Divij Joshi
* Debra Erickson
* Borhane Blili-Hamelin
* Beth M. Duckles
* Bernease Herman
* Bernd Durrwachter

Thumbnail photo by USGS on [Unsplash](https://unsplash.com/photos/3F2YdXjJMCI).

